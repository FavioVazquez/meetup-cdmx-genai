{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3997491e7649e9f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Notebook 3: H2OGPTe with RAG\n",
    "## Favio VÃ¡zquez\n",
    "\n",
    "![](front.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1018494823bf456",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Configuration and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907e9af1a712a288",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from h2ogpte import H2OGPTE\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "h2ogpte_keys = {\n",
    "            \"address\": os.getenv(\"H2OGPTE_ADDRESS\"),\n",
    "            \"api_key\": os.getenv(\"H2OGPTE_KEY\"),\n",
    "        }\n",
    "\n",
    "client = H2OGPTE(**h2ogpte_keys)\n",
    "LLM = 'mistralai/Mixtral-8x7B-Instruct-v0.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de97a498e75bfb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Creating the Collection and Ingesting the document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444b6ca9d4f4c2d0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client.list_recent_collections(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9103f38e6d21763",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name = \"meetup\"\n",
    "\n",
    "collection_id = None\n",
    "print(\"Recent collections:\")\n",
    "recent_collections = client.list_recent_collections(0, 1000)\n",
    "for c in recent_collections:\n",
    "    if c.name == name and c.document_count:\n",
    "        collection_id = c.id\n",
    "        break\n",
    "\n",
    "# Create Collection\n",
    "if collection_id is None:\n",
    "    print(f\"Creating collection: {name} ...\")\n",
    "    collection_id = client.create_collection(\n",
    "        name=name, description=\"Meetup demo collection\"\n",
    "    )\n",
    "    print(f\"New collection: {collection_id} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dd677924b8ebd2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collection_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe164750e9ef5859",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client.list_documents_in_collection(collection_id, 0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbaa33a0400747a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = 'blackholes.pdf'\n",
    "\n",
    "filename = str(filepath).split('/')[-1]\n",
    "print(f'Ingesting file {filename}')\n",
    "documents = client.list_documents_in_collection(collection_id, 0, 1000)\n",
    "document_ids = [d.id for d in documents if d.name == filename]\n",
    "\n",
    "if len(document_ids) == 0:\n",
    "    with open(filepath, 'rb') as f:\n",
    "        doc = client.upload(filename, f)\n",
    "    client.ingest_uploads(collection_id, [doc])\n",
    "    print(f'File {filename} ingested')\n",
    "else:\n",
    "    print(f'File {filename} already ingested')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8850ad52ab3801",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Talking to the model and PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f4055e79ae2661",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## This is going to give an answer without using the PDF\n",
    "answer = client.answer_question(question=\"What is the document about?\", llm=LLM).content\n",
    "print(f\"{LLM}: {answer}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b8856a15370211",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prompts = {\n",
    "    'system_prompt': \"\"\"You are a virtual assistant that helps physicists in interpretations and analysis of report and documents.\n",
    "Only answer the questions in English and never use another language.\n",
    "Answer the questions with information provided in the context, do not create any information.\"\"\",\n",
    "\n",
    "    'pre_prompt_query': \"\"\"Consider the following document and answer the following questions based on the provided document.\"\"\",\n",
    "    'prompt_query': \"\"\"Answer the following question based on the provided document.\"\"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b2f7a47a5905e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "documents = client.list_documents_in_collection(collection_id, offset=0, limit=99)\n",
    "doc = documents[0]\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e824caa174e81e0b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Asking questions to the document itself with a chat session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0f4e7d8b54e543",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collection_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8014dfee1bfec801",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "question = \"What is the document about?\"\n",
    "\n",
    "chat_session_id = client.create_chat_session(collection_id)\n",
    "with client.connect(chat_session_id) as session:\n",
    "    response = session.query(\n",
    "        question,\n",
    "        llm=LLM).content\n",
    "    print(response, flush=True)\n",
    "\n",
    "client.delete_chat_sessions([chat_session_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f69389105ac5dc9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "question = \"Can black holes evaporate?\"\n",
    "\n",
    "chat_session_id = client.create_chat_session(collection_id)\n",
    "with client.connect(chat_session_id) as session:\n",
    "    response = session.query(\n",
    "        question,\n",
    "        llm=LLM).content\n",
    "    print(response, flush=True)\n",
    "\n",
    "client.delete_chat_sessions([chat_session_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2ec35287070b8b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Summarizing the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395086d52e26a385",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating a summary of the document\n",
    "\n",
    "message = \"Create a summary of the document, including the most important information and conclusions\"\n",
    "\n",
    "summary = client.summarize_document(\n",
    "    document_id=doc.id,\n",
    "    max_num_chunks=20,\n",
    "    llm=LLM,\n",
    "    system_prompt=prompts['system_prompt'],\n",
    "    pre_prompt_summary=prompts['pre_prompt_query'],\n",
    "    prompt_summary=message,\n",
    ")\n",
    "\n",
    "print(summary.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfde237ed55ce4d6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Configuring the chat session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88345bc8fc1ebcc0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "llm_args = {\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 0.1,\n",
    "}\n",
    "\n",
    "message = \"Create a summary of the document, including the most important information and conclusions\"\n",
    "\n",
    "chat_session_id = client.create_chat_session(collection_id)\n",
    "args = {\n",
    "    \"system_prompt\": prompts['system_prompt'],\n",
    "    \"pre_prompt_query\": prompts['pre_prompt_query'],\n",
    "    \"prompt_query\": prompts['prompt_query'],\n",
    "    \"message\": message,\n",
    "    \"timeout\": 120,\n",
    "    \"llm\": LLM,\n",
    "    'rag_config':{\"rag_type\": 'rag+'},\n",
    "    \"llm_args\": llm_args\n",
    "    }\n",
    "\n",
    "with client.connect(chat_session_id) as session:\n",
    "    response = session.query(**args)\n",
    "client.delete_chat_sessions([chat_session_id])\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d777e2d45f3b9e4b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "llm_args = {\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 1,\n",
    "}\n",
    "\n",
    "message = \"Create a summary of the document, including the most important information and conclusions\"\n",
    "\n",
    "chat_session_id = client.create_chat_session(collection_id)\n",
    "args = {\n",
    "    \"system_prompt\": prompts['system_prompt'],\n",
    "    \"pre_prompt_query\": prompts['pre_prompt_query'],\n",
    "    \"prompt_query\": prompts['prompt_query'],\n",
    "    \"message\": message,\n",
    "    \"timeout\": 120,\n",
    "    \"llm\": LLM,\n",
    "    'rag_config':{\"rag_type\": 'rag+'},\n",
    "    \"llm_args\": llm_args\n",
    "    }\n",
    "\n",
    "with client.connect(chat_session_id) as session:\n",
    "    response = session.query(**args)\n",
    "client.delete_chat_sessions([chat_session_id])\n",
    "\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
